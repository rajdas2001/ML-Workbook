{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SpaCy Basics",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOaTsZj5090u41xNKpv7zv2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajdas2001/ML-Workbook/blob/main/NLP-SpaCy_Basics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pbH5GcUBZYML"
      },
      "source": [
        "# Intro"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B22DgmmqZaN4"
      },
      "source": [
        "Data comes in many different forms: time stamps, sensor readings, images, categorical labels, and so much more. But text is still some of the most valuable data out there for those who know how to use it.\n",
        "\n",
        "In this course about Natural Language Processing (NLP), you will use the leading NLP library (spaCy) to take on some of the most important tasks in working with text.\n",
        "\n",
        "By the end, you will be able to use spaCy for:\n",
        "\n",
        "* Basic text processing and pattern matching\n",
        "* Building machine learning models with text\n",
        "* Representing text with word embeddings that numerically capture the meaning of words and documents"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aa7VNJPUaDVD"
      },
      "source": [
        "# NLP with spaCy\n",
        "\n",
        "spaCy is the leading library for NLP, and it has quickly become one of the most popular Python frameworks. Most people find it intuitive, and it has excellent documentation.\n",
        "\n",
        "spaCy relies on models that are language-specific and come in different sizes. You can load a spaCy model with spacy.load.\n",
        "\n",
        "For example, here's how you would load the English language model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DNl6LZ2iZWoH"
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "doc = nlp(\"Tea is healthy and calming, don't you think?\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8KW2fDbSaV6n"
      },
      "source": [
        "# Tokenizing\n",
        "\n",
        "This returns a document object that contains tokens. A token is a unit of text in the document, such as individual words and punctuation. SpaCy splits contractions like \"don't\" into two tokens, \"do\" and \"n't\". You can see the tokens by iterating through the document."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xG5O9otsafMj",
        "outputId": "bce88290-7609-4881-eee1-c726bbe01f1e"
      },
      "source": [
        "for token in doc:\n",
        "    print(token)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tea\n",
            "is\n",
            "healthy\n",
            "and\n",
            "calming\n",
            ",\n",
            "do\n",
            "n't\n",
            "you\n",
            "think\n",
            "?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icVzlKWEbIFJ"
      },
      "source": [
        "# Text preprocessing\n",
        "\n",
        "There are a few types of preprocessing to improve how we model with words. The first is \"lemmatizing.\" The \"lemma\" of a word is its base form. For example, \"walk\" is the lemma of the word \"walking\". So, when you lemmatize the word walking, you would convert it to walk.\n",
        "\n",
        "It's also common to remove stopwords. Stopwords are words that occur frequently in the language and don't contain much information. English stopwords include \"the\", \"is\", \"and\", \"but\", \"not\".\n",
        "\n",
        "With a spaCy token, token.lemma_ returns the lemma, while token.is_stop returns a boolean True if the token is a stopword (and False otherwise)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7vKzwhRXas2n",
        "outputId": "d94510ec-00d8-47c3-cd3b-328fe5029c47"
      },
      "source": [
        "print(f\"Token \\t\\tLemma \\t\\tStopword\".format('Token', 'Lemma', 'Stopword'))\n",
        "print(\"-\"*40)\n",
        "for token in doc:\n",
        "    print(f\"{str(token)}\\t\\t{token.lemma_}\\t\\t{token.is_stop}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token \t\tLemma \t\tStopword\n",
            "----------------------------------------\n",
            "Tea\t\ttea\t\tFalse\n",
            "is\t\tbe\t\tTrue\n",
            "healthy\t\thealthy\t\tFalse\n",
            "and\t\tand\t\tTrue\n",
            "calming\t\tcalm\t\tFalse\n",
            ",\t\t,\t\tFalse\n",
            "do\t\tdo\t\tTrue\n",
            "n't\t\tnot\t\tTrue\n",
            "you\t\t-PRON-\t\tTrue\n",
            "think\t\tthink\t\tFalse\n",
            "?\t\t?\t\tFalse\n"
          ]
        }
      ]
    }
  ]
}