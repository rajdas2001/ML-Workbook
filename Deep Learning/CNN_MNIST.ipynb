{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN_MNIST",
      "provenance": [],
      "authorship_tag": "ABX9TyN0GTOv0oR8wDOiEIrUPEP6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rajdas2001/ML-Workbook/blob/main/CNN_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KehQnfbH6OMK"
      },
      "source": [
        "# Handwritten Digit Classification"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xFk_hpQuud_n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3bb34d9-7a20-4a01-fc4a-cd4fe3961945"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.utils import np_utils\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "#we can load the MNIST dataset from Keras datasets\n",
        "#60.000 training samples and 10.000 images in test set\n",
        "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
        "print(\"X_train original shape\", X_train.shape)\n",
        "print(\"y_train original shape\", y_train.shape)\n",
        "print(\"X_test original shape\", X_test.shape)\n",
        "print(\"y_test original shape\", y_test.shape)\n",
        "\n",
        "#let's polit a grayscale image with the label\n",
        "#plt.imshow(X_train[0], cmap='gray')\n",
        "#plt.title('Class '+ str(y_train[0]))\n",
        "\n",
        "#tensorflow can handle format: (batch,height,width,channel)\n",
        "features_train = X_train.reshape(X_train.shape[0], 28, 28, 1)\n",
        "features_test = X_test.reshape(X_test.shape[0], 28, 28, 1)\n",
        "\n",
        "features_train = features_train.astype('float32')\n",
        "features_test = features_test.astype('float32')\n",
        "\n",
        "#very similar to min-max normalization: we transform the values\n",
        "#within the range [0,1] as usual\n",
        "features_train/=255\n",
        "features_test/=255\n",
        "\n",
        "#we have 10 output classes we want to end up with one hot\n",
        "#encoding as we have seen for the Iris-dataset\n",
        "# 2 -> [0 0 1 0 0 0 0 0 0 0 ]\n",
        "targets_train = np_utils.to_categorical(y_train, 10)\n",
        "targets_test = np_utils.to_categorical(y_test, 10)\n",
        "\n",
        "#let's build the Convolutional Neural Network (CNN)\n",
        "model = Sequential()\n",
        "\n",
        "#input is a 28x28 pixels image\n",
        "#32 is the number of filters - (3,3) size of the filter\n",
        "model.add(Conv2D(32, (3, 3), input_shape=(28,28,1)))\n",
        "model.add(Activation('relu'))\n",
        "#normalizes the activations in the previous layer after the convolutional phase\n",
        "#transformation maintains the mean activation close to 0 std close to 1\n",
        "#the scale of each dimension remains the same\n",
        "#reduces running-time of training significantly\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(32, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64,(3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, (3, 3)))\n",
        "model.add(Activation('relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "#flattening layer \n",
        "model.add(Flatten())\n",
        "# Fully connected layer\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dense(512))\n",
        "model.add(Activation('relu'))\n",
        "model.add(BatchNormalization())\n",
        "#regularization helps to avoid overfitting\n",
        "model.add(Dropout(0.3))\n",
        "model.add(Dense(10,activation=\"softmax\"))\n",
        "\n",
        "#model.summary()\n",
        "\n",
        "#multiclass classification: cross-entropy loss-function with ADAM optimizer\n",
        "model.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n",
        "#model.fit(features_train, targets_train, batch_size=128, epochs=2, validation_data=(features_test,targets_test), verbose=1)\n",
        "\n",
        "#score = model.evaluate(features_test, targets_test)\n",
        "#print('Test accuracy: %.2f' % score[1])\n",
        "\n",
        "#data augmentation helps to reduce overfitting\n",
        "train_generator = ImageDataGenerator(rotation_range=7, width_shift_range=0.05, shear_range=0.2,\n",
        "                         height_shift_range=0.07, zoom_range=0.05)\n",
        "\n",
        "test_genrator = ImageDataGenerator()\n",
        "\n",
        "train_generator = train_generator.flow(features_train, targets_train, batch_size=64)\n",
        "test_generator = test_genrator.flow(features_test, targets_test, batch_size=64)\n",
        "\n",
        "model.fit_generator(train_generator, steps_per_epoch=60000//64, epochs=5, \n",
        "                    validation_data=test_generator, validation_steps=10000//64)\n",
        "\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n",
            "X_train original shape (60000, 28, 28)\n",
            "y_train original shape (60000,)\n",
            "X_test original shape (10000, 28, 28)\n",
            "y_test original shape (10000,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1915: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "937/937 [==============================] - 192s 185ms/step - loss: 0.2538 - accuracy: 0.9244 - val_loss: 0.0917 - val_accuracy: 0.9730\n",
            "Epoch 2/5\n",
            "937/937 [==============================] - 173s 184ms/step - loss: 0.0657 - accuracy: 0.9794 - val_loss: 0.0407 - val_accuracy: 0.9861\n",
            "Epoch 3/5\n",
            "937/937 [==============================] - 174s 185ms/step - loss: 0.0425 - accuracy: 0.9871 - val_loss: 0.0292 - val_accuracy: 0.9903\n",
            "Epoch 4/5\n",
            "937/937 [==============================] - 174s 186ms/step - loss: 0.0417 - accuracy: 0.9877 - val_loss: 0.0251 - val_accuracy: 0.9912\n",
            "Epoch 5/5\n",
            "937/937 [==============================] - 174s 185ms/step - loss: 0.0349 - accuracy: 0.9895 - val_loss: 0.0271 - val_accuracy: 0.9916\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff011e6b5d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    }
  ]
}